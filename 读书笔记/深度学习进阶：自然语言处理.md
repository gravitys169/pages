
## 神经网络复习
- 神经网络具有输入层、隐藏层和输出层
- 通过全连接层进行线性变换，通过激活函数进行非线性变换
- 全连接层和 mini-batch 处理都可以写成矩阵计算
- 使用误差反向传播法可以高效地求解神经网络的损失的梯度
- 使用计算图能够将神经网络中发生的处理可视化，这有助于理解正向传播和反向传播
- 在神经网络的实现中，通过将组件模块化为层，可以简化实现
- 数据的位精度和 GPU 并行计算对神经网络的高速化非常重要