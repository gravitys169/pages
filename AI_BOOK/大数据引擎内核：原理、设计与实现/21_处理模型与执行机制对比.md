# 第21章：处理模型与执行机制对比 (Processing Model & Execution Mechanism Comparison)

在对比了宏观架构之后，本章将深入引擎的"心脏"——处理模型与执行机制。这决定了引擎如何看待数据（批、流、微批）、何时执行计算（惰性、流水线）以及如何在集群中推进任务（DAG、MPP Stage）。这些差异直接影响了引擎的延迟、吞吐量和应用场景。

## 21.1 Batch vs Micro-Batch vs True Streaming vs Interactive Query

数据处理模型定义了引擎处理数据的基本范式。

1.  **Spark: Batch & Micro-Batch**
    *   **Batch (核心):** Spark Core和Spark SQL最初是为**大规模批处理**设计的。它将整个数据集（或其一个大分区）视为一个处理单元，完成一个Stage的所有Task后，再开始下一个Stage。
    *   **Micro-Batch (Structured Streaming):** Structured Streaming采用**微批处理**模型模拟流处理。它将连续的数据流切分成一系列小的批次（通常是秒级或亚秒级），然后使用Spark SQL的批处理引擎来处理这些小批次。这提供了与批处理一致的API和Exactly-Once保证，但本质上仍是基于批次的调度和执行，延迟相对较高。
    *   **Continuous Processing (实验性):** Spark也曾尝试引入低延迟的连续处理模式，但目前主流仍是Micro-Batch。

2.  **Flink: True Streaming (兼具强大的Batch)**
    *   **True Streaming (核心):** Flink被设计为**真正的流处理引擎**。它逐条处理记录（或小的Buffer），数据在算子之间以**流水线 (Pipelined)** 方式传输，无需等待整个批次完成。这使得Flink能够实现非常低的**事件处理延迟**。
    *   **Batch as Bounded Stream:** Flink通过将批处理视为**有界流 (Bounded Stream)** 来统一批流处理。其流处理引擎同样可以高效地处理有界数据，并在某些场景下（如排序、聚合）采用优化的批处理执行策略。

3.  **Presto/Trino: Interactive Query (基于Pipelined Batch)**
    *   **Interactive Query:** Presto/Trino的目标是**低延迟的交互式SQL查询**。它接收SQL查询，将其分解为一系列可在Worker节点上并行执行的Stage和Task。
    *   **Pipelined Batch Execution:** 虽然是处理离线数据（批数据），但其执行方式是**流水线式**的。数据一旦在一个算子处理完成，就立即被发送到下游算子进行处理，而不是等待整个Stage完成。这使得结果可以尽快地返回给用户，提供了交互式的体验。

**处理模型对比总结:**

| 引擎        | 主要处理模型          | 流处理实现      | 批处理实现          | 核心特点                                        |
| :---------- | :-------------------- | :-------------- | :------------------ | :---------------------------------------------- |
| **Spark**   | Batch                 | Micro-Batch     | 核心能力 (RDD/SQL)  | 擅长大规模批处理，流处理为微批模拟，延迟相对较高    |
| **Flink**   | True Streaming        | 核心能力        | Batch as Bounded Stream | 原生流处理，低延迟，批流统一API和引擎              |
| **Presto/Trino**| Interactive Query     | 不支持          | Pipelined Execution | 专注于低延迟SQL查询，流水线执行，非存储数据      |

## 21.2 Lazy Evaluation vs Pipelined Execution

评估策略决定了计算何时真正发生。

1.  **Spark: Lazy Evaluation (惰性求值)**
    *   **机制:** Spark中的转换操作（Transformations, 如 `map`, `filter`, `select`）是惰性的。它们仅仅构建了RDD/Dataset的计算**逻辑计划 (Lineage)**，并不会立即执行。只有当遇到行动操作（Actions, 如 `count`, `collect`, `save`）时，Spark才会根据Lineage生成物理执行计划（DAG of Stages），并真正触发计算。
    *   **优点:**
        *   **优化:** 可以在执行前对整个计算链进行优化（例如，合并操作、谓词下推）。
        *   **效率:** 避免计算不需要的中间结果。
    *   **缺点:** 对于需要快速看到部分结果的场景（如交互式查询），延迟较高。

2.  **Flink: Pipelined Execution (流水线执行)**
    *   **机制:** Flink采用**流水线执行**模型。一旦数据记录进入第一个算子并被处理，它就会被立即发送到下游算子进行处理，数据在算子链中持续流动。这适用于低延迟的流处理。
    *   **优点:**
        *   **低延迟:** 数据处理延迟极低，适合实时性要求高的场景。
        *   **资源效率:** 避免了大规模中间结果的物化存储（数据在网络Buffer中流动）。
    *   **挑战:** 需要有效的反压机制来处理上下游速率不匹配的问题。

3.  **Presto/Trino: Pipelined Execution (流水线执行)**
    *   **机制:** 类似于Flink，Presto/Trino也采用**流水线执行**。一个Stage内的算子，以及跨Stage的数据传输（通过Exchange Operator），都是流水线式的。一个Task处理完一部分数据（一个Page）后，会立即发送给下游Task。
    *   **优点:**
        *   **低延迟:** 使得查询结果能够尽快返回给用户，实现交互式体验。
    *   **挑战:** 内存管理变得复杂，需要精确控制每个查询和算子的内存使用，并可能需要Spill to Disk。

**评估/执行策略对比:**

| 引擎        | 评估/执行策略       | 特点                                                 |
| :---------- | :------------------ | :--------------------------------------------------- |
| **Spark**   | Lazy Evaluation     | 转换操作构建计划，行动操作触发执行，利于全局优化         |
| **Flink**   | Pipelined Execution | 数据在算子间持续流动，低延迟，需要反压机制             |
| **Presto/Trino**| Pipelined Execution | Stage内和Stage间流水线执行，低延迟交互式查询，内存管理关键 |

## 21.3 DAG执行 vs Stage-based MPP执行

执行机制描述了引擎如何在集群中组织和推进计算任务。

1.  **Spark: DAG of Stages Execution**
    *   **模型:** Spark将用户代码生成的逻辑计划转换为一个**有向无环图 (DAG)**。这个DAG根据**宽依赖 (Shuffle)** 被划分为若干个**Stage (阶段)**。同一个Stage内的任务（Task）可以并行执行，且没有Shuffle依赖。只有当前一个Stage的所有Task都成功完成后，下一个Stage才能开始执行。
    *   **特点:**
        *   **容错:** 基于Stage的执行模型简化了容错。如果一个Stage失败，只需重新计算该Stage即可（利用RDD Lineage）。
        *   **批处理优化:** 适合需要全局排序或聚合的大规模批处理。
        *   **延迟:** Stage之间的屏障（Barrier）导致执行延迟相对较高。

2.  **Flink: DAG of Operators Execution (Continuous Flow)**
    *   **模型:** Flink也将作业转换为一个**DAG (StreamGraph -> JobGraph -> ExecutionGraph)**，但其执行方式是**连续流 (Continuous Flow)**。数据源源不断地流入DAG，并在算子之间以流水线方式处理和传输。Task一旦部署并开始运行，就会持续处理流入的数据，除非遇到外部阻塞（如等待Checkpoint完成）或反压。
    *   **特点:**
        *   **低延迟:** 数据持续流动，没有显式的Stage边界阻塞。
        *   **流式优化:** 设计上天然适合流处理。
        *   **容错:** 依赖Checkpoint机制进行状态恢复。

3.  **Presto/Trino: Stage-based MPP Execution (Pipelined)**
    *   **模型:** Presto/Trino也将查询计划划分为**Stage**，Stage之间通过**Exchange Operator**进行数据传输。但是，与Spark不同，Stage之间的执行是**流水线式 (Pipelined)** 的，而不是严格的串行阻塞。一个下游Stage的Task可以在上游Stage的Task产生部分输出后就开始处理。
    *   **驱动方式:** Presto/Trino的执行是**Output Buffer驱动**的。当一个Task的Output Buffer有空间时，它才会向上游请求数据并执行计算。当下游无法消费时，上游Task会阻塞。
    *   **特点:**
        *   **MPP并行:** Stage内的Task在Worker上大规模并行执行。
        *   **流水线:** Stage间流水线执行以降低延迟。
        *   **交互式:** 适合快速返回部分结果的交互式查询。

**执行机制对比总结:**

| 引擎        | 执行模型                      | Stage间关系       | 驱动方式          | 核心特点                                               |
| :---------- | :---------------------------- | :---------------- | :---------------- | :----------------------------------------------------- |
| **Spark**   | DAG of Stages                 | 阻塞 (Barrier)    | Stage完成驱动     | 基于Stage容错，适合批处理，延迟高                         |
| **Flink**   | DAG of Operators (Continuous Flow)| 流水线            | 数据驱动/事件驱动 | 低延迟，持续处理，依赖Checkpoint容错                     |
| **Presto/Trino**| Stage-based MPP (Pipelined)   | 流水线            | Output Buffer驱动 | MPP并行+流水线，低延迟交互式，Worker间直接交换数据         |

**总结:** Spark以其基于Stage的批处理模型和惰性求值在吞吐量和全局优化方面表现出色，但在延迟上有所牺牲。Flink以其真正的流处理模型和流水线执行机制在低延迟和事件驱动处理上占优，并通过批流统一适应批处理。Presto/Trino则结合了MPP架构和流水线执行，专注于提供低延迟的交互式SQL查询体验。理解这些处理模型和执行机制的差异对于选择合适的引擎来满足特定的业务需求至关重要。 