## 概括1111

**一句话：用一个NameNode节点记录一个文件打散到不同DataNode节点的文件块，由依托本地文件系统的DataNode提供文件读取服务**

Hadoop分布式文件系统（Hadoop Distributed File System），由1个NameNode与N个DataNode组成。

![5f7580af4f749a861c39dd54adcf5f7d_800x437.png@900-0-90-f.png](https://s2.loli.net/2024/02/04/sEMHFrmkYWA27gp.png)
## HDFS中NameNode的作用

- NameNode负责管理HDFS中的元数据，包括文件和目录的层次结构、文件块的位置信息、访问权限和文件属性等。元数据通常存储在NameNode的内存中，并且通过持久化到本地磁盘上的编辑日志和镜像文件来提供持久性。
- 数据块的映射：NameNode维护了文件块和数据节点之间的映射关系。**它记录了每个文件块所在的数据节点和副本的位置信息**。这样，当客户端请求读取或写入文件时，NameNode可以告知客户端从哪些数据节点读取或写入数据。
- Secondary Namenode 主要是为了辅助主 Namenode 的检查点生成，而不是在主 Namenode 故障时提供替代。
	- Namenode 会定期生成文件系统的检查点，以防止元数据的丢失。生成检查点的过程涉及遍历整个文件系统的命名空间，并将当前的元数据信息写入磁盘。这个操作可能在大规模文件系统上是一个昂贵的过程。
	- Secondary Namenode 负责定期从主 Namenode 处获取整个文件系统的镜像，并将其写入本地磁盘。然后，主 Namenode 在生成检查点时只需要参考这个镜像，而不是遍历整个文件系统。
## HDFS中文件与文件块的关系：

- 文件切割成块：当一个文件被上传到HDFS时，文件会被切分成固定大小的数据块（通常为128MB或256MB）。文件的最后一个块可能会小于固定大小。

- 块的分布：每个数据块都会被复制到多个数据节点上，以实现数据的冗余和故障容忍性。HDFS使用默认的副本系数（通常为3）来确定每个数据块的复制数量。副本被分布在不同的数据节点上，可以跨多个机架以提高容错性。

- 块的存储：数据块在数据节点上以本地文件的形式进行存储。每个数据节点都有一个或多个存储目录，用于存放数据块。存储目录通常位于本地文件系统上，例如ext4或XFS。
	- 本地文件系统与hdfs宏观原理类似，分为元数据与数据块，以ext4为例：
		- **inode元数据与块数据**：
			- `ext4` 将文件系统的数据划分为固定大小的块（通常为4KB）。这有助于更高效地管理文件存储。
			- `ext4` 使用 inode（索引节点）来存储文件的元数据，如文件大小、权限、所有者等。每个文件和目录都有一个唯一的 inode。
		- **可靠性日志（Journaling）**：
		    - `ext4` 支持日志功能，这意味着在执行文件系统操作时，会先将操作记录到一个事务日志（journal）中。这可以提高文件系统的容错性，防止在系统崩溃或断电时造成数据损坏。 通过使用日志，`ext4` 可以更快速地进行文件系统的恢复。

- 块的标识：每个数据块都有一个全局唯一的标识符，称为块ID（Block ID）。块ID是通过对文件的路径和偏移量进行哈希计算而生成的。这个块ID被用于唯一标识数据块，并在HDFS中进行块的定位和管理。

- 数据节点的角色：每个数据节点都承载了一些数据块的副本。它负责存储和管理这些数据块的副本，并在需要时向客户端提供数据。数据节点还会定期向NameNode报告其存储的块的信息。

  

## HDFS系统常见的瓶颈与挑战：

- 副本数量：HDFS采用数据冗余的方式来提供数据的容错性。如果副本数量设置过高，会增加存储成本和网络开销。但如果副本数量设置过低，可能会降低系统的可靠性。

    - 解决方案：通过EC而非副本的方式，例如[OceanStor Pacific系列](https://carrier.huawei.com/~/media/cnbgv2/download/products/it-new/oceanstor-pacific.pdf)采用领先的弹性EC数据冗余保护机制，相较传统多副本方式，EC技术将硬盘空间利用率提升近2倍。

- NameNode的性能：HDFS的元数据由一个单独的节点，即NameNode进行管理。如果NameNode成为系统的瓶颈，可能会导致整个系统的性能下降。大量的文件和目录、频繁的元数据操作和访问热点可能对NameNode产生压力。

    - 解决方案：使用NameNode联邦，减少单一NameNode管理的数据文件数量

- 小文件问题：HDFS适用于大型文件的存储和处理，但如果有大量的小文件，可能会导致存储空间的浪费和NameNode的负载增加。这是因为每个文件都会占用一定的存储空间和元数据信息。

    - 合并小文件，这里的小文件指的是Hive Metastore中一个表或分区下对应的多个小文件。如果单个表本来就很小，那么这个问题无法解决

- 数据倾斜：在HDFS中，如果数据不均匀地分布在各个数据块中，可能会导致某些节点负载过重，而其他节点处于空闲状态。这种数据倾斜可能会导致资源利用不均衡和性能下降。

    - 依靠后台调度，将热点数据块搬移到非热点datanode上